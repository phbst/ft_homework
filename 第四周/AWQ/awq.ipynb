{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-29T09:15:09.528902600Z",
     "start_time": "2024-01-29T09:15:08.595299800Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'awq'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mawq\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AutoAWQForCausalLM\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AutoTokenizer\n\u001B[0;32m      4\u001B[0m model_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfacebook/opt-6.7b\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'awq'"
     ]
    }
   ],
   "source": [
    "from awq import AutoAWQForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "quant_path = \"facebook/opt-2.7b-awq\"\n",
    "model_path = \"facebook/opt-6.7b\"\n",
    "quant_config = {\"zero_point\": True, \"q_group_size\": 128, \"w_bit\": 4, \"version\": \"GEMM\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 量化"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc45930aacfb8843"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 第一方式"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b94340c73d2e7f32"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = AutoAWQForCausalLM.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "model.quantize(tokenizer, quant_config=quant_config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b3ac01c0102a47f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 与transformers 兼容"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8d25669ddb3b04bc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import AutoConfig,AwqConfig"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T09:39:51.974318400Z",
     "start_time": "2024-01-29T09:39:51.962045500Z"
    }
   },
   "id": "6986466fedcb66e0",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 修改配置文件以使其与transformers集成兼容\n",
    "quantization_config = AwqConfig(\n",
    "    bits=quant_config[\"w_bit\"],\n",
    "    group_size=quant_config[\"q_group_size\"],\n",
    "    zero_point=quant_config[\"zero_point\"],\n",
    "    version=quant_config[\"version\"].lower(),\n",
    ").to_dict()\n",
    "\n",
    "# 预训练的transformers模型存储在model属性中，我们需要传递一个字典\n",
    "model.model.config.quantization_config = quantization_config"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d228aaf9fc986a3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.save_quantized(quant_path)\n",
    "tokenizer.save_pretrained(quant_path)  # 保存分词器"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b2b216382e27ef2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 调用模型"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed7466eb822013f0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(quant_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(quant_path, device_map=\"cuda\").to(0)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b75d2ccf8f21836"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def generate_text(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(0)\n",
    "\n",
    "    out = model.generate(**inputs, max_new_tokens=64)\n",
    "    return tokenizer.decode(out[0], skip_special_tokens=True)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5eb5250224dc32d7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "result = generate_text(\"Merry Christmas! I'm glad to\")\n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac43a2b8abcee0d7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e86e9d9282405f9f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6b015c3dbee87e57"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
