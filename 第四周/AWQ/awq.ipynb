{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T09:15:09.528902600Z",
     "start_time": "2024-01-29T09:15:08.595299800Z"
    },
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-02-16T08:37:51.014712Z",
     "iopub.status.busy": "2024-02-16T08:37:51.013948Z",
     "iopub.status.idle": "2024-02-16T08:38:03.456342Z",
     "shell.execute_reply": "2024-02-16T08:38:03.455535Z",
     "shell.execute_reply.started": "2024-02-16T08:37:51.014673Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-02-16 16:37:57.457508: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-16 16:37:58.040007: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-16 16:37:58.040048: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-16 16:37:58.043889: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-16 16:37:58.398353: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-16 16:37:58.400817: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-16 16:38:00.298381: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from awq import AutoAWQForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "quant_path = \"./awq_model\"\n",
    "model_path = \"/mnt/data/opt-6.7b\"\n",
    "quant_config = {\"zero_point\": True, \"q_group_size\": 128, \"w_bit\": 4, \"version\": \"GEMM\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a84ee9e-d51f-4d33-826a-3640631f5e2b",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-02-16T07:40:52.559099Z",
     "iopub.status.busy": "2024-02-16T07:40:52.558352Z",
     "iopub.status.idle": "2024-02-16T07:41:41.460321Z",
     "shell.execute_reply": "2024-02-16T07:41:41.459479Z",
     "shell.execute_reply.started": "2024-02-16T07:40:52.559067Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:22<00:00, 11.34s/it]\n"
     ]
    }
   ],
   "source": [
    "model = AutoAWQForCausalLM.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94340c73d2e7f32",
   "metadata": {},
   "source": [
    "## 第一种方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec8c438a-fabf-440a-b74c-0bbf38b75afa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T06:41:20.001462Z",
     "iopub.status.busy": "2024-02-16T06:41:20.000705Z",
     "iopub.status.idle": "2024-02-16T06:43:00.918633Z",
     "shell.execute_reply": "2024-02-16T06:43:00.917414Z",
     "shell.execute_reply.started": "2024-02-16T06:41:20.001411Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "Couldn't reach 'mit-han-lab/pile-val-backup' on the Hub (ConnectionError)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mConnectionError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mquantize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquant_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquant_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/awq/models/base.py:89\u001B[0m, in \u001B[0;36mBaseAWQForCausalLM.quantize\u001B[0;34m(self, tokenizer, quant_config, calib_data, split, text_column, duo_scaling, modules_to_not_convert)\u001B[0m\n\u001B[1;32m     83\u001B[0m \u001B[38;5;129m@torch\u001B[39m\u001B[38;5;241m.\u001B[39mno_grad()\n\u001B[1;32m     84\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mquantize\u001B[39m(\u001B[38;5;28mself\u001B[39m, tokenizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, quant_config\u001B[38;5;241m=\u001B[39m{},\n\u001B[1;32m     85\u001B[0m                    calib_data: Union[\u001B[38;5;28mstr\u001B[39m, List[\u001B[38;5;28mstr\u001B[39m]]\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpileval\u001B[39m\u001B[38;5;124m\"\u001B[39m, \n\u001B[1;32m     86\u001B[0m                    split\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m, text_column\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m\"\u001B[39m, duo_scaling\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, modules_to_not_convert\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m     87\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mquant_config: AwqConfig \u001B[38;5;241m=\u001B[39m AwqConfig\u001B[38;5;241m.\u001B[39mfrom_dict(quant_config)\n\u001B[0;32m---> 89\u001B[0m     quantizer \u001B[38;5;241m=\u001B[39m \u001B[43mAwqQuantizer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     90\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mquant_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mw_bit\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mquant_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mq_group_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     91\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mquant_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mversion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcalib_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msplit\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtext_column\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mduo_scaling\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodules_to_not_convert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodules_to_not_convert\u001B[49m\n\u001B[1;32m     92\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     93\u001B[0m     quantizer\u001B[38;5;241m.\u001B[39mquantize()\n\u001B[1;32m     95\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_quantized \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/awq/quantize/quantizer.py:36\u001B[0m, in \u001B[0;36mAwqQuantizer.__init__\u001B[0;34m(self, awq_model, model, tokenizer, w_bit, group_size, version, calib_data, split, text_column, duo_scaling, modules_to_not_convert)\u001B[0m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mduo_scaling \u001B[38;5;241m=\u001B[39m duo_scaling\n\u001B[1;32m     35\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodules_to_not_convert \u001B[38;5;241m=\u001B[39m modules_to_not_convert \u001B[38;5;28;01mif\u001B[39;00m modules_to_not_convert \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m []\n\u001B[0;32m---> 36\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodules, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodule_kwargs, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minps \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minit_quant\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/awq/quantize/quantizer.py:320\u001B[0m, in \u001B[0;36mAwqQuantizer.init_quant\u001B[0;34m(self, n_samples, seqlen)\u001B[0m\n\u001B[1;32m    318\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minit_quant\u001B[39m(\u001B[38;5;28mself\u001B[39m, n_samples\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m128\u001B[39m, seqlen\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m512\u001B[39m):\n\u001B[1;32m    319\u001B[0m     modules \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mawq_model\u001B[38;5;241m.\u001B[39mget_model_layers(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel)\n\u001B[0;32m--> 320\u001B[0m     samples \u001B[38;5;241m=\u001B[39m \u001B[43mget_calib_dataset\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    321\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcalib_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtokenizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_samples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_samples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mblock_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mseqlen\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    322\u001B[0m \u001B[43m        \u001B[49m\u001B[43msplit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtext_column\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtext_column\u001B[49m\n\u001B[1;32m    323\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    324\u001B[0m     samples \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat(samples, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m    326\u001B[0m     inps \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/awq/utils/calib_data.py:11\u001B[0m, in \u001B[0;36mget_calib_dataset\u001B[0;34m(data, tokenizer, n_samples, block_size, split, text_column)\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpileval\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m---> 11\u001B[0m         dataset \u001B[38;5;241m=\u001B[39m \u001B[43mload_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmit-han-lab/pile-val-backup\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msplit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mvalidation\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     12\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     13\u001B[0m         dataset \u001B[38;5;241m=\u001B[39m load_dataset(data, split\u001B[38;5;241m=\u001B[39msplit)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/datasets/load.py:2523\u001B[0m, in \u001B[0;36mload_dataset\u001B[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001B[0m\n\u001B[1;32m   2518\u001B[0m verification_mode \u001B[38;5;241m=\u001B[39m VerificationMode(\n\u001B[1;32m   2519\u001B[0m     (verification_mode \u001B[38;5;129;01mor\u001B[39;00m VerificationMode\u001B[38;5;241m.\u001B[39mBASIC_CHECKS) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m save_infos \u001B[38;5;28;01melse\u001B[39;00m VerificationMode\u001B[38;5;241m.\u001B[39mALL_CHECKS\n\u001B[1;32m   2520\u001B[0m )\n\u001B[1;32m   2522\u001B[0m \u001B[38;5;66;03m# Create a dataset builder\u001B[39;00m\n\u001B[0;32m-> 2523\u001B[0m builder_instance \u001B[38;5;241m=\u001B[39m \u001B[43mload_dataset_builder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2524\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2525\u001B[0m \u001B[43m    \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2526\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2527\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata_files\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_files\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2528\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2529\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfeatures\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfeatures\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2530\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdownload_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdownload_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2531\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdownload_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdownload_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2532\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2533\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtoken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2534\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2535\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrust_remote_code\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2536\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_require_default_config_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   2537\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mconfig_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2538\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2540\u001B[0m \u001B[38;5;66;03m# Return iterable dataset in case of streaming\u001B[39;00m\n\u001B[1;32m   2541\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m streaming:\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/datasets/load.py:2195\u001B[0m, in \u001B[0;36mload_dataset_builder\u001B[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, use_auth_token, storage_options, trust_remote_code, _require_default_config_name, **config_kwargs)\u001B[0m\n\u001B[1;32m   2193\u001B[0m     download_config \u001B[38;5;241m=\u001B[39m download_config\u001B[38;5;241m.\u001B[39mcopy() \u001B[38;5;28;01mif\u001B[39;00m download_config \u001B[38;5;28;01melse\u001B[39;00m DownloadConfig()\n\u001B[1;32m   2194\u001B[0m     download_config\u001B[38;5;241m.\u001B[39mstorage_options\u001B[38;5;241m.\u001B[39mupdate(storage_options)\n\u001B[0;32m-> 2195\u001B[0m dataset_module \u001B[38;5;241m=\u001B[39m \u001B[43mdataset_module_factory\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2196\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2197\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2198\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdownload_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdownload_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2199\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdownload_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdownload_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2200\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2201\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata_files\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_files\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2202\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2203\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrust_remote_code\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2204\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_require_default_config_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_require_default_config_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2205\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_require_custom_configs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mbool\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mconfig_kwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2206\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2207\u001B[0m \u001B[38;5;66;03m# Get dataset builder class from the processing script\u001B[39;00m\n\u001B[1;32m   2208\u001B[0m builder_kwargs \u001B[38;5;241m=\u001B[39m dataset_module\u001B[38;5;241m.\u001B[39mbuilder_kwargs\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/datasets/load.py:1846\u001B[0m, in \u001B[0;36mdataset_module_factory\u001B[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001B[0m\n\u001B[1;32m   1841\u001B[0m             \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(e1, \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m):\n\u001B[1;32m   1842\u001B[0m                 \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m(\n\u001B[1;32m   1843\u001B[0m                     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCouldn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt find a dataset script at \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrelative_to_absolute_path(combined_path)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m or any data file in the same directory. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1844\u001B[0m                     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCouldn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt find \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m on the Hugging Face Hub either: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(e1)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me1\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1845\u001B[0m                 ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1846\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m e1 \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1847\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1848\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m(\n\u001B[1;32m   1849\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCouldn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt find a dataset script at \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrelative_to_absolute_path(combined_path)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m or any data file in the same directory.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1850\u001B[0m     )\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/datasets/load.py:1780\u001B[0m, in \u001B[0;36mdataset_module_factory\u001B[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001B[0m\n\u001B[1;32m   1771\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# noqa catch any exception of hf_hub and consider that the dataset doesn't exist\u001B[39;00m\n\u001B[1;32m   1772\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\n\u001B[1;32m   1773\u001B[0m         e,\n\u001B[1;32m   1774\u001B[0m         (\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1778\u001B[0m         ),\n\u001B[1;32m   1779\u001B[0m     ):\n\u001B[0;32m-> 1780\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCouldn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt reach \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m on the Hub (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(e)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1781\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m404\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(e):\n\u001B[1;32m   1782\u001B[0m         msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m doesn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt exist on the Hub\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "\u001B[0;31mConnectionError\u001B[0m: Couldn't reach 'mit-han-lab/pile-val-backup' on the Hub (ConnectionError)"
     ]
    }
   ],
   "source": [
    "model.quantize(tokenizer, quant_config=quant_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d25669ddb3b04bc",
   "metadata": {},
   "source": [
    "## 与transformers 兼容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6986466fedcb66e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T09:39:51.974318400Z",
     "start_time": "2024-01-29T09:39:51.962045500Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-02-16T07:34:16.425976Z",
     "iopub.status.busy": "2024-02-16T07:34:16.425055Z",
     "iopub.status.idle": "2024-02-16T07:34:16.430778Z",
     "shell.execute_reply": "2024-02-16T07:34:16.429663Z",
     "shell.execute_reply.started": "2024-02-16T07:34:16.425926Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoConfig,AwqConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d228aaf9fc986a3",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-02-16T07:34:16.433975Z",
     "iopub.status.busy": "2024-02-16T07:34:16.433250Z",
     "iopub.status.idle": "2024-02-16T07:34:16.438807Z",
     "shell.execute_reply": "2024-02-16T07:34:16.437665Z",
     "shell.execute_reply.started": "2024-02-16T07:34:16.433928Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 修改配置文件以使其与transformers集成兼容\n",
    "quantization_config = AwqConfig(\n",
    "    bits=quant_config[\"w_bit\"],\n",
    "    group_size=quant_config[\"q_group_size\"],\n",
    "    zero_point=quant_config[\"zero_point\"],\n",
    "    version=quant_config[\"version\"].lower(),\n",
    ").to_dict()\n",
    "\n",
    "# 预训练的transformers模型存储在model属性中，我们需要传递一个字典\n",
    "model.model.config.quantization_config = quantization_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51e8348b-cb1d-4200-886d-803b77596075",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T07:34:16.440088Z",
     "iopub.status.busy": "2024-02-16T07:34:16.439817Z",
     "iopub.status.idle": "2024-02-16T07:34:16.445589Z",
     "shell.execute_reply": "2024-02-16T07:34:16.444555Z",
     "shell.execute_reply.started": "2024-02-16T07:34:16.440061Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'quant_method': <QuantizationMethod.AWQ: 'awq'>, 'bits': 4, 'group_size': 128, 'zero_point': True, 'version': <AWQLinearVersion.GEMM: 'gemm'>, 'backend': <AwqBackendPackingMethod.AUTOAWQ: 'autoawq'>, 'fuse_max_seq_len': None, 'modules_to_fuse': None, 'do_fuse': False}\n"
     ]
    }
   ],
   "source": [
    "print(model.model.config.quantization_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6da8a10b-99d8-4d43-8762-27f143eec41d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T07:34:16.446895Z",
     "iopub.status.busy": "2024-02-16T07:34:16.446639Z",
     "iopub.status.idle": "2024-02-16T07:34:16.528761Z",
     "shell.execute_reply": "2024-02-16T07:34:16.527677Z",
     "shell.execute_reply.started": "2024-02-16T07:34:16.446870Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./awq_model/tokenizer_config.json',\n",
       " './awq_model/special_tokens_map.json',\n",
       " './awq_model/vocab.json',\n",
       " './awq_model/merges.txt',\n",
       " './awq_model/added_tokens.json',\n",
       " './awq_model/tokenizer.json')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(quant_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f0705b-7469-4fc9-b9c4-5b3943ff4965",
   "metadata": {},
   "source": [
    "# 这里不知道为什么运行时（model.save_quantized(quant_path)），会出现kernel died的情况，求解答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2b216382e27ef2",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-02-16T07:34:16.530493Z",
     "iopub.status.busy": "2024-02-16T07:34:16.529897Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:`quant_config.json` is being deprecated in the future in favor of quantization_config in config.json.\n"
     ]
    }
   ],
   "source": [
    "model.save_quantized(quant_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208cc930-864f-42f2-b497-3c2197148e90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed7466eb822013f0",
   "metadata": {},
   "source": [
    "## 调用模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b75d2ccf8f21836",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-02-16T08:38:03.458522Z",
     "iopub.status.busy": "2024-02-16T08:38:03.457902Z",
     "iopub.status.idle": "2024-02-16T08:39:21.000959Z",
     "shell.execute_reply": "2024-02-16T08:39:21.000106Z",
     "shell.execute_reply.started": "2024-02-16T08:38:03.458490Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:51<00:00, 25.56s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_path = \"/mnt/data/opt-6.7b\"\n",
    "model = AutoAWQForCausalLM.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5eb5250224dc32d7",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-02-16T08:39:21.002751Z",
     "iopub.status.busy": "2024-02-16T08:39:21.002466Z",
     "iopub.status.idle": "2024-02-16T08:39:21.007338Z",
     "shell.execute_reply": "2024-02-16T08:39:21.006268Z",
     "shell.execute_reply.started": "2024-02-16T08:39:21.002726Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_text(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(0)\n",
    "\n",
    "    out = model.generate(**inputs, max_new_tokens=64)\n",
    "    return tokenizer.decode(out[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac43a2b8abcee0d7",
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = generate_text(\"Merry Christmas! I'm glad to\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86e9d9282405f9f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b015c3dbee87e57",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
