{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "initial_id",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-01-30T08:44:55.728423Z",
     "iopub.status.busy": "2024-01-30T08:44:55.727675Z",
     "iopub.status.idle": "2024-01-30T08:44:55.733692Z",
     "shell.execute_reply": "2024-01-30T08:44:55.732700Z",
     "shell.execute_reply.started": "2024-01-30T08:44:55.728390Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModel,BitsAndBytesConfig\n",
    "from transformers import Trainer,TrainingArguments\n",
    "from peft import get_peft_model, prepare_model_for_kbit_training, TaskType, LoraConfig\n",
    "from peft.utils import TRANSFORMERS_MODELS_TO_LORA_TARGET_MODULES_MAPPING\n",
    "#配置一下全局超参数\n",
    "base_model_path=\"/mnt/data/chatglm3-6b-model\"\n",
    "train_data_path=\"./static/datasets.csv\"\n",
    "seed=42\n",
    "max_inputs=512\n",
    "max_outputs=1536\n",
    "lora_rank=16\n",
    "lora_dropout=0.05\n",
    "lora_alpha=32\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb7832a-9f62-40ae-baec-5f410069d4ff",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# 数据是gpt生成的，虚拟女友"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7fc0958554248b1",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-01-30T08:44:59.967655Z",
     "iopub.status.busy": "2024-01-30T08:44:59.966730Z",
     "iopub.status.idle": "2024-01-30T08:45:01.385663Z",
     "shell.execute_reply": "2024-01-30T08:45:01.384676Z",
     "shell.execute_reply.started": "2024-01-30T08:44:59.967616Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#加载数据\n",
    "\n",
    "dataset=load_dataset(\"csv\",data_files=train_data_path)\n",
    "\n",
    "#加载分词器\n",
    "\n",
    "\n",
    "tokenizer=AutoTokenizer.from_pretrained(base_model_path,trust_remote_code=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b840267-572c-4ae9-87bd-18f934aefeed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T08:45:01.390092Z",
     "iopub.status.busy": "2024-01-30T08:45:01.389636Z",
     "iopub.status.idle": "2024-01-30T08:45:01.394428Z",
     "shell.execute_reply": "2024-01-30T08:45:01.393748Z",
     "shell.execute_reply.started": "2024-01-30T08:45:01.390066Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['man', 'wemen'],\n",
       "        num_rows: 169\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a0b502990944890",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-01-30T08:45:01.395780Z",
     "iopub.status.busy": "2024-01-30T08:45:01.395287Z",
     "iopub.status.idle": "2024-01-30T08:45:01.415272Z",
     "shell.execute_reply": "2024-01-30T08:45:01.414644Z",
     "shell.execute_reply.started": "2024-01-30T08:45:01.395752Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#使用分词器对数据处理，进行分词，且加上特殊符号\n",
    "def tokenizer_function(example, tokenizer,ignore_lable_id=-100):\n",
    "    question=example[\"man\"]\n",
    "    answer=example[\"wemen\"]\n",
    "    q_ids=tokenizer.encode(question,add_special_tokens=False)\n",
    "    a_ids=tokenizer.encode(answer,add_special_tokens=False)\n",
    "    if len(q_ids)>max_inputs-2:\n",
    "        q_ids=q_ids[:max_inputs-2]\n",
    "    if len(a_ids)>max_outputs-1:\n",
    "        a_ids=a_ids[:max_outputs-1]\n",
    "    inputs_ids=tokenizer.build_inputs_with_special_tokens(q_ids,a_ids)\n",
    "    question_length=len(q_ids)+2\n",
    "    inputs_labels=[ignore_lable_id]*question_length+inputs_ids[question_length:]\n",
    "    return {\"input_ids\":inputs_ids,\"labels\":inputs_labels}\n",
    "\n",
    "\n",
    "tokenized_dataset=dataset[\"train\"].map(lambda example:tokenizer_function(example,tokenizer),batched=False,remove_columns=[\"wemen\",\"man\"])\n",
    "\n",
    "tokenized_dataset = tokenized_dataset.shuffle(seed=seed)\n",
    "tokenized_dataset = tokenized_dataset.flatten_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20e427ce-8861-41cc-8983-9b9e7672ef5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T08:45:01.417351Z",
     "iopub.status.busy": "2024-01-30T08:45:01.416838Z",
     "iopub.status.idle": "2024-01-30T08:45:01.421324Z",
     "shell.execute_reply": "2024-01-30T08:45:01.420696Z",
     "shell.execute_reply.started": "2024-01-30T08:45:01.417324Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'labels'],\n",
       "    num_rows: 169\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ccba835-d0fa-45cf-850d-9af0f42d1c68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T08:45:01.422397Z",
     "iopub.status.busy": "2024-01-30T08:45:01.422136Z",
     "iopub.status.idle": "2024-01-30T08:45:01.428391Z",
     "shell.execute_reply": "2024-01-30T08:45:01.427704Z",
     "shell.execute_reply.started": "2024-01-30T08:45:01.422374Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import ClassLabel, Sequence\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "        elif isinstance(typ, Sequence) and isinstance(typ.feature, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda x: [typ.feature.names[i] for i in x])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "869e4613-44bc-4973-bd89-c72ac555e97b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T08:45:01.429768Z",
     "iopub.status.busy": "2024-01-30T08:45:01.429393Z",
     "iopub.status.idle": "2024-01-30T08:45:01.440548Z",
     "shell.execute_reply": "2024-01-30T08:45:01.439921Z",
     "shell.execute_reply.started": "2024-01-30T08:45:01.429744Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64790, 64792, 30910, 37040, 31123, 54546, 55411, 55058, 31708, 55465, 44248, 31123, 56558, 54607, 54546, 33338, 41071, 54547, 55296, 55674, 31404, 36718, 54547, 55296, 31514, 54728, 54929, 55268, 33876, 55227, 36229, 44248, 31123, 54546, 33021, 54701, 42354, 55296, 31926, 31404, 2]</td>\n",
       "      <td>[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 36718, 54547, 55296, 31514, 54728, 54929, 55268, 33876, 55227, 36229, 44248, 31123, 54546, 33021, 54701, 42354, 55296, 31926, 31404, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[64790, 64792, 30910, 39661, 31123, 31869, 39229, 50444, 33748, 36354, 31123, 32193, 31897, 31740, 31669, 54537, 31155, 30910, 37040, 31123, 41608, 34281, 33458, 31740, 55282, 31155, 38307, 31983, 34319, 54591, 31123, 39807, 39508, 31674, 31902, 54664, 31740, 31123, 34110, 32190, 33588, 31155, 31925, 54622, 32814, 50444, 54537, 31123, 34318, 31937, 34897, 31903, 39396, 55282, 31514, 32469, 34329, 31844, 35122, 56645, 31155, 54725, 41487, 31903, 41230, 32316, 37316, 31123, 31803, 38149, 31123, 32817, 33514, 35263, 35341, 31802, 51965, 32402, 55282, 31155, 32194, 53125, 31123, 40207, 54701, 50444, 33748, 55370, 31123, 39661, 31155, 2]</td>\n",
       "      <td>[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 30910, 37040, 31123, 41608, 34281, 33458, 31740, 55282, 31155, 38307, 31983, 34319, 54591, 31123, 39807, 39508, 31674, 31902, 54664, 31740, 31123, 34110, 32190, 33588, 31155, 31925, 54622, 32814, 50444, 54537, 31123, 34318, 31937, 34897, 31903, 39396, 55282, 31514, 32469, 34329, 31844, 35122, 56645, 31155, 54725, 41487, 31903, 41230, 32316, 37316, 31123, 31803, 38149, 31123, 32817, 33514, 35263, 35341, 31802, 51965, 32402, 55282, 31155, 32194, 53125, 31123, 40207, 54701, 50444, 33748, 55370, 31123, 39661, 31155, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[64790, 64792, 36474, 54591, 31123, 31869, 33071, 35367, 31514, 30910, 39661, 31123, 35398, 33071, 54657, 32884, 55282, 31155, 33057, 50165, 31123, 53128, 55771, 55771, 31123, 32805, 49495, 32729, 36804, 31155, 45360, 43324, 38493, 32693, 40657, 55282, 31514, 2]</td>\n",
       "      <td>[-100, -100, -100, -100, -100, -100, -100, -100, -100, 30910, 39661, 31123, 35398, 33071, 54657, 32884, 55282, 31155, 33057, 50165, 31123, 53128, 55771, 55771, 31123, 32805, 49495, 32729, 36804, 31155, 45360, 43324, 38493, 32693, 40657, 55282, 31514, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[64790, 64792, 30910, 39661, 31123, 54546, 31869, 32056, 42917, 31123, 33149, 57350, 54738, 31123, 54868, 33149, 55450, 31155, 30910, 54835, 33519, 31123, 36731, 54622, 32483, 31624, 54657, 34697, 31123, 39229, 33485, 56389, 54668, 56123, 55491, 31123, 40322, 37972, 32024, 54868, 31123, 32043, 33168, 57149, 54578, 33503, 38425, 31123, 34933, 31897, 54591, 54727, 54530, 31155, 2]</td>\n",
       "      <td>[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 30910, 54835, 33519, 31123, 36731, 54622, 32483, 31624, 54657, 34697, 31123, 39229, 33485, 56389, 54668, 56123, 55491, 31123, 40322, 37972, 32024, 54868, 31123, 32043, 33168, 57149, 54578, 33503, 38425, 31123, 34933, 31897, 54591, 54727, 54530, 31155, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[64790, 64792, 36474, 31717, 55398, 31123, 41608, 31897, 54622, 32103, 33115, 32566, 54631, 31155, 30910, 58070, 31123, 38505, 36778, 31876, 54536, 32566, 31627, 33115, 40895, 31123, 31828, 35094, 31820, 31818, 44393, 43963, 31822, 33115, 31155, 2]</td>\n",
       "      <td>[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 30910, 58070, 31123, 38505, 36778, 31876, 54536, 32566, 31627, 33115, 40895, 31123, 31828, 35094, 31820, 31818, 44393, 43963, 31822, 33115, 31155, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[64790, 64792, 53456, 35416, 31749, 54652, 37909, 33893, 54948, 34317, 54537, 31123, 32044, 31643, 34628, 33764, 54537, 31123, 31894, 51688, 42001, 42425, 48726, 48046, 31155, 30910, 58070, 31123, 52029, 32131, 31897, 31123, 35416, 32536, 45520, 32436, 32696, 34317, 54542, 35550, 31123, 31772, 34992, 31820, 31676, 32088, 33075, 31155, 2]</td>\n",
       "      <td>[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 30910, 58070, 31123, 52029, 32131, 31897, 31123, 35416, 32536, 45520, 32436, 32696, 34317, 54542, 35550, 31123, 31772, 34992, 31820, 31676, 32088, 33075, 31155, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[64790, 64792, 34211, 32483, 54701, 40120, 35574, 33450, 31123, 35323, 54948, 54661, 54537, 31404, 30910, 58147, 31404, 35574, 32967, 33114, 33085, 53757, 31810, 55282, 31123, 41236, 54622, 32300, 31688, 31642, 31850, 33634, 31514, 2]</td>\n",
       "      <td>[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 30910, 58147, 31404, 35574, 32967, 33114, 33085, 53757, 31810, 55282, 31123, 41236, 54622, 32300, 31688, 31642, 31850, 33634, 31514, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[64790, 64792, 53456, 48525, 39534, 31809, 32697, 54530, 55551, 55323, 31123, 54591, 34311, 56645, 31404, 30910, 58070, 31123, 32664, 55551, 55323, 55282, 31514, 54929, 38953, 55370, 31404, 2]</td>\n",
       "      <td>[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 30910, 58070, 31123, 32664, 55551, 55323, 55282, 31514, 54929, 38953, 55370, 31404, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[64790, 64792, 53779, 31624, 32483, 54657, 36858, 31123, 32507, 40296, 54539, 31155, 34211, 32185, 31822, 34697, 31123, 31624, 32967, 34778, 32774, 31669, 35933, 31155, 34607, 33085, 40167, 32187, 31796, 31638, 31862, 32721, 31635, 31123, 36545, 45342, 54622, 31155, 31925, 31123, 33021, 31937, 31674, 31902, 56645, 31123, 31844, 38921, 55433, 42917, 31155, 2]</td>\n",
       "      <td>[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 34211, 32185, 31822, 34697, 31123, 31624, 32967, 34778, 32774, 31669, 35933, 31155, 34607, 33085, 40167, 32187, 31796, 31638, 31862, 32721, 31635, 31123, 36545, 45342, 54622, 31155, 31925, 31123, 33021, 31937, 31674, 31902, 56645, 31123, 31844, 38921, 55433, 42917, 31155, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[64790, 64792, 53456, 51879, 33149, 56750, 57763, 31123, 34110, 54574, 32056, 55079, 55014, 31155, 30910, 39661, 31123, 31844, 40914, 31404, 44104, 33485, 34649, 54819, 54802, 31404, 54622, 33671, 49682, 31123, 32192, 31627, 44762, 36310, 32321, 31155, 31844, 34855, 31123, 32248, 32553, 43146, 54747, 31123, 31855, 34022, 49665, 55187, 57204, 37915, 55555, 31123, 54688, 41406, 35087, 54563, 32122, 31123, 35805, 32523, 49060, 37900, 31155, 35094, 31820, 56024, 41107, 31123, 36280, 55379, 55176, 32176, 40102, 31123, 33485, 31996, 31155, 32192, 31627, 31123, 32192, 32010, 31920, 31123, 31749, 55283, 54718, 33533, 32088, 31404, 2]</td>\n",
       "      <td>[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 30910, 39661, 31123, 31844, 40914, 31404, 44104, 33485, 34649, 54819, 54802, 31404, 54622, 33671, 49682, 31123, 32192, 31627, 44762, 36310, 32321, 31155, 31844, 34855, 31123, 32248, 32553, 43146, 54747, 31123, 31855, 34022, 49665, 55187, 57204, 37915, 55555, 31123, 54688, 41406, 35087, 54563, 32122, 31123, 35805, 32523, 49060, 37900, 31155, 35094, 31820, 56024, 41107, 31123, 36280, 55379, 55176, 32176, 40102, 31123, 33485, 31996, 31155, 32192, 31627, 31123, 32192, 32010, 31920, 31123, 31749, 55283, 54718, 33533, 32088, 31404, 2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(tokenized_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9192250acab59cc6",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-01-30T08:45:01.441641Z",
     "iopub.status.busy": "2024-01-30T08:45:01.441383Z",
     "iopub.status.idle": "2024-01-30T08:45:01.447919Z",
     "shell.execute_reply": "2024-01-30T08:45:01.447154Z",
     "shell.execute_reply.started": "2024-01-30T08:45:01.441619Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Data_Collector:\n",
    "    def __init__(self,pad_token_id:int,max_length:int=2048,ignore_lable_id:int=-100):\n",
    "        self.pad_token_id=pad_token_id\n",
    "        self.max_length=max_length\n",
    "        self.ignore_lable_id=ignore_lable_id\n",
    "    def __call__(self,batch_data):\n",
    "        len_list=[len(i[\"input_ids\"]) for i in batch_data]\n",
    "        batch_max_len=max(len_list)\n",
    "        input_ids,labels=[],[]\n",
    "        for len_of_d,d in sorted(zip(len_list,batch_data),key=lambda x:-x[0]):\n",
    "            pad_len=batch_max_len-len_of_d\n",
    "            input_id=d[\"input_ids\"]+[self.pad_token_id]*pad_len\n",
    "            lable=d[\"labels\"]+[self.ignore_lable_id]*pad_len\n",
    "            if batch_max_len>self.max_length:\n",
    "                input_id=input_ids[:self.max_length]\n",
    "                label=lable[:self.max_length]\n",
    "            input_ids.append(torch.LongTensor(input_id))\n",
    "            labels.append(torch.LongTensor(lable))\n",
    "        input_ids=torch.stack(input_ids)\n",
    "        labels=torch.stack(labels)\n",
    "        return {\"input_ids\":input_ids,\"labels\":labels}\n",
    "data_collector=Data_Collector(pad_token_id=tokenizer.pad_token_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3531b104-92da-4842-b3bf-c7c502ad7b6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d20c62c6b319a91c",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-01-30T08:45:04.716147Z",
     "iopub.status.busy": "2024-01-30T08:45:04.715549Z",
     "iopub.status.idle": "2024-01-30T08:47:23.490887Z",
     "shell.execute_reply": "2024-01-30T08:47:23.490061Z",
     "shell.execute_reply.started": "2024-01-30T08:45:04.716109Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 7/7 [02:14<00:00, 19.17s/it]\n",
      "You are using an old version of the checkpointing format that is deprecated (We will also silently ignore `gradient_checkpointing_kwargs` in case you passed it).Please update to the new format on your modeling file. To use the new format, you need to completely remove the definition of the method `_set_gradient_checkpointing` in your model.\n"
     ]
    }
   ],
   "source": [
    "#加载模型\n",
    "q_config=BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "base_model=AutoModel.from_pretrained(base_model_path,quantization_config=q_config,device_map=\"auto\",trust_remote_code=True)\n",
    "base_model.supports_gradient_checkpointing = True\n",
    "base_model.config.use_cache = False\n",
    "\n",
    "kbit_model=prepare_model_for_kbit_training(base_model)\n",
    "target_model=TRANSFORMERS_MODELS_TO_LORA_TARGET_MODULES_MAPPING['chatglm']\n",
    "\n",
    "lora_config=LoraConfig(\n",
    "    target_modules=target_model,\n",
    "    r=lora_rank,\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    bias='none',\n",
    "    inference_mode=False,\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "qlora_model=get_peft_model(kbit_model,lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d992d586adbf049",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-01-30T08:47:23.492647Z",
     "iopub.status.busy": "2024-01-30T08:47:23.492371Z",
     "iopub.status.idle": "2024-01-30T08:47:23.502606Z",
     "shell.execute_reply": "2024-01-30T08:47:23.501952Z",
     "shell.execute_reply.started": "2024-01-30T08:47:23.492622Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.19.24, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#构建训练器\n",
    "output_dir=\"phb/chatglm3-ft\"\n",
    "training_args=TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=1,\n",
    "    learning_rate=1e-3,\n",
    "    num_train_epochs=3,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=1,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=10,\n",
    "    optim=\"adamw_torch\",\n",
    "    fp16=True\n",
    ")\n",
    "trainer=Trainer(\n",
    "    model=qlora_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    data_collator=data_collector\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74e3e4ab910a0d8a",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-01-30T08:47:23.503710Z",
     "iopub.status.busy": "2024-01-30T08:47:23.503464Z",
     "iopub.status.idle": "2024-01-30T08:48:34.168992Z",
     "shell.execute_reply": "2024-01-30T08:48:34.168269Z",
     "shell.execute_reply.started": "2024-01-30T08:47:23.503687Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 01:09, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.455500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.015700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.487900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.377100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.011200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.389800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.033100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.539600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.846000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.745200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.670900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.495100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.542000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.397600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.846700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.368800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2.380300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.450900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.424300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.551000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2.222000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>3.767600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.928000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.923100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.168900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>2.140900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.672600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.994600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.912600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.935800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>2.001100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>2.140500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.851200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.855400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.847100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>2.077900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.792900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.717300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>2.083900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.738900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>2.210400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.956600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>1.900700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.277100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.552100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.547200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>1.583500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.602000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1.322800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.599600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>1.448700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.289500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>1.428400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>1.323700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.309300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>1.372500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>1.454400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>1.361800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>1.224700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.296800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>1.453800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>1.314000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>1.501900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>1.338100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>1.688900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>1.598500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory phb/chatglm3-ft/checkpoint-10 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "Checkpoint destination directory phb/chatglm3-ft/checkpoint-20 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "Checkpoint destination directory phb/chatglm3-ft/checkpoint-30 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "Checkpoint destination directory phb/chatglm3-ft/checkpoint-40 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "Checkpoint destination directory phb/chatglm3-ft/checkpoint-50 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "Checkpoint destination directory phb/chatglm3-ft/checkpoint-60 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=66, training_loss=2.0720901615691907, metrics={'train_runtime': 70.2552, 'train_samples_per_second': 7.217, 'train_steps_per_second': 0.939, 'total_flos': 2193800282247168.0, 'train_loss': 2.0720901615691907, 'epoch': 3.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "622deb10b9902151",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-01-30T08:48:39.493252Z",
     "iopub.status.busy": "2024-01-30T08:48:39.492483Z",
     "iopub.status.idle": "2024-01-30T08:48:39.554341Z",
     "shell.execute_reply": "2024-01-30T08:48:39.553503Z",
     "shell.execute_reply.started": "2024-01-30T08:48:39.493208Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.model.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1c1b891de934c2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e888c649-72a7-46da-b6f5-d2411f117088",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8422005ae62035aa",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fd1757-c50c-4984-be8b-c6189976faf8",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936b851e2f985a8c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8fe5be-8b2e-4ed5-a2d9-1983727a3d26",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622c3988-d078-45cd-8d78-8ce4f880ab3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a40a3be-0bb4-4b60-b8a8-4e81d4155129",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3443f9-61e7-483d-8d76-63f37f1b3b55",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4ed050-f55e-4c56-a17d-d5bffbcf94b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b86fd09-90e5-43eb-b3f0-e10a51a7e494",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e252129d-3aef-4a10-8302-0e220d8b16ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81b6585-306e-4c43-bfd7-cde6fd86becd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760a7d66-2db6-498c-8562-80bca1899c2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
